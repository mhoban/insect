---
title: "The 'insect' R package tutorial 1: a gentle introduction"
author: "Shaun Wilkinson"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: insect.bib
csl: bioinformatics.csl
vignette: >
  %\VignetteIndexEntry{Introduction to the insect package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE, message = FALSE, warning = FALSE}
#knitr::opts_chunk$set(out.width='750px', dpi=200)
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

--------------------------------------------------------------------------------


##Introduction
Welcome to the **insect** R package, 
a pipeline for the analysis of next generation sequencing (NGS) amplicon 
libraries using **in**formatic **se**quence **c**lassification **t**rees. 
The pipeline employs a machine-learning approach that 
uses a set of *training* sequences (usually derived from barcode 
sequencing of individual specimens of known taxonomy) 
to 'learn' a classification tree, 
which is then used to assign taxonomic IDs to a set of 
*query* sequences generated from a NGS platform such as Illumina MiSeq. 
The package also includes a suite of functions 
for FASTQ/FASTA sequence parsing, de-multiplexing, 
paired-end read stitching, primer trimming, quality filtering, 
de-replication, re-replication, 
and many more useful operations.
These functions are designed for use on 
workstations with multiple-processors, 
but can also be used on standard laptop and desktop computers 
provided the user doesn't mind waiting a little longer for the results.
While not a prerequisite, the pipeline is designed to be used in conjunction with the **ape**
package [@Paradis2004; @Paradis2012], which contains memory-efficient
binary formats for DNAs and amino acids ("DNAbin" and "AAbin" objects)
among many other useful features.
The **insect** package is ideal for processing environmental DNA 
(eDNA) meta-barcode libraries and single-source NGS/Sanger 
amplicon sequences.


The most time-consuming part of the process 
generally involves building the classification tree. 
For example, a training dataset consisting of 
300,000 COI sequences recently took around one week 
to learn on a workstation with 
48 logical processors (2.3GHz) and 64 GB RAM. 
To produce a classification tree, the **learn** function 
recursively partitions the training sequences 
(a top-down/divisive approach as opposed to 
bottom-up/agglomerative methods such as UPGMA and neighbor-joining).
The dataset is initially divided in two, and a profile hidden Markov model
is derived for each subset for downstream classification of query sequences
(see Durbin et al. [-@Durbin1998] for a detailed description of these models). 
The lowest common taxonomic rank of each subset is also stored at each new node, 
also for downstream query sequence classification.
The partitioning and model training procedure then continues 
recursively, splitting the training data into smaller and 
smaller subsets.

The **insect** classification trees are amplicon specific, 
so a unique tree is generally required for each primer set. 
However, trees are already available for some of the more common barcoding primers 
[here](https://osf.io/fvyub/). 
The package also includes functions and instructions 
for downloading and filtering training sequences from GenBank 
(including a "virtual PCR" tool and a quality filter for lineage metadata), 
performing the tree-learning operation and tabulating the output classifications, 
though these methods are beyond the scope of this introductory tutorial.
New trees are constantly being added to the collection, 
so please feel free to suggest a barcoding primer set with 
which to generate a tree and we will endeavor to add it to the list.

Once a classification tree has been loaded, 
query sequences obtained using the same primer set can be classified to produce 
taxonomic IDs with an associated degree of confidence.
The classification algorithm works as follows:
starting from the root node of the classification tree, 
the *likelihood* of the query sequence 
(the log-probability of the sequence given a model) 
is computed for each of the models at the child nodes 
using the forward algorithm (see Durbin et al. [-@Durbin1998]). 
The competing likelihood values are then compared by computing 
their Akaike weights [see @Johnson2004], 
and one model is overwhelmingly more likely to have produced the 
sequence than the other, that child node is chosen and the taxon ID
is updated accordingly, to the taxon ID stored at the node. 

This procedure is repeated, continuing down the tree until 
either an inconclusive result is returned from a model comparison test
(i.e. the Akaike weight is lower than a pre-defined threshold, usually 0.9), 
or a terminal leaf node is reached, at which point a species-level 
classification is generally returned. 
The algorithm outputs a taxonomic ID, its rank 
(i.e. species, genus, family, etc), and the
Akaike weight of the best model at the final node.
Note that the default behavior is for the Akaike weight to 'decay' 
as it moves down the tree, by computing the cumulative product 
of all preceding Akaike weight values. 
This is perhaps an overly conservative approach, 
but it minimizes the chance of generating type I errors. 

In addition to the two key functions `learn` and `classify`, 
the package includes several tools to encode the entire work-flow from 
raw sequence data input to tabular output. 
This tutorial will gently guide users through the pipeline using an example dataset
of COI sequences derived from Autonomous Reef Monitoring Structures (ARMS)
in Timor-Leste, amplified using the barcoding primers 
mlCOIintF and jgHCO2198 (GGWACWGGWTGAACWGTWTAYCCYCC and 
TAIACYTCIGGRTGICCRAARAAYCA, respectively; Leray et al. [-@Leray2013]).


##A working example
First download and install the latest development version of the 
package by following the instructions in the package README 
[here](https://github.com/shaunpwilkinson/insect). 
Then load the package by running

```{R}
library(insect)
```

A zip file containing two FASTQ files 
(representing the forward and reverse reads from the same sample) 
as well as the classification tree can 
be found [here](https://osf.io/2xqmw/).
Once the archive is downloaded and the contents extracted to the 
working directory, the FASTQ files are initially read into R as either concatenated
upper-case character strings or binary "DNAbin" objects, with "quality" attributes. 
In this example we will opt for the former by setting `bin = FALSE`, 
since the character strings are perhaps a little more intuitive for beginners. 
Intermediate/advanced users who are familiar with the **ape** package
may prefer to work with "DNAbin" objects by retaining the default setting of
`bin = TRUE`.

```{R}
R1 <- readFASTQ("S1_L001_R1_001.fastq", bin = FALSE)
R2 <- readFASTQ("S1_L001_R2_001.fastq", bin = FALSE)
```

The newly created R1 and R2 objects are the same length, 
and have the same names apart from 
a single digit that specifies the read number.
The first couple of R1 sequences and their names can be viewed as follows:

```{R}
head(R1, 2)
```

The next step is to stitch the forward and reverse reads together to create a single 
vector of sequences. The `stitch` function performs this operation, as well as 
optionally removing any sequences that don't contain the primer sequences,
trimming the primers off the ones that do, and orientating the sequences 
in the 5' -> 3' direction.
The optional primer filter-trim and sequence orientation is 
activated by passing the primer sequences to the function 
(again either as character strings or "DNAbin" objects). 
Note that this operation will take a few seconds to process, 
since the function uses the computationally intensive Needlemanâ€“Wunsch 
algorithm to find the optimal alignments for the paired sequences. 
The operation can be sped up considerably by setting `cores = 2` or
more if using a computer with multiple processors. 

```{R}
mlCOIintF <- "GGWACWGGWTGAACWGTWTAYCCYCC"
jgHCO2198 <- "TAIACYTCIGGRTGICCRAARAAYCA"
x <- stitch(R1, R2, up = mlCOIintF, down = jgHCO2198)
```

Of the orginal 1000, 304 sequences were retained and stitched together. 
The sequence set now needs further filtering to remove low-quality
reads, ambiguous base calls and singletons.
The function `qfilter` is a quality control function that can 
be used to apply any or all of these filters.
The default behavior is to remove any sequences with a mean quality 
score of less than 30, 
those that contain ambiguous base calls,
those that appear only once in the dataset (singletons),
and those with length outside the range of 50 - 500 nucleotides inclusive.
To disable any of the filters, simply set the parameter value to `NULL`.
In this example we will stick with the default settings, except that we will
change the acceptable length range to 250 - 350 bp.

```{R}
x <- qfilter(x, minlength = 250, maxlength = 350)
```

This has whittled the dataset down 140 sequences.
For the purposes of this exercise we will reduce the dataset down even further, 
by only retaining the unique sequences for input into the classification tree.
Note that this won't result in a significant speedup, since the `classify` function
automatically dereplicates and rereplicates the sequence set before and after 
classification anyway. It will just provide us with a simplified output
to interpret for the tutorial.


```{r}
x <- dereplicate(x)
```

Note that we use `dereplicate` instead of `unique` here since the latter would strip the "names" 
attributes from the sequences, which will be useful for downstream analyses.
The `dereplicate` function also stores the information necessary to re-replicate the sequence 
set at a later time if needed. 
Now we have 13 unique, high quality sequences that occur more than 
once in the dataset, are between 250 and 350 nucleotides long, 
and are free of ambiguous base calls.

The final step is to load the classification tree and run the `classify` function to 
assign taxonomic IDs and associated Akaike weight confidence scores 
(between 0 and 1, with anything over 0.9 signifying strong confidence).
Again this may take a minute or two to process, 
because `classify` also uses computationally intensive dynamic
programming to find the likelihoods of the sequences
at each node of the classification tree. 
This function is also able to be run in parallel by setting the `cores` 
argument to 2 or more depending on the number available 
(tip: run `parallel::detectCores()` if you are unsure).

```{r}
load("tree.RData")
y <- classify(x, tree)
print(unname(y))
```

The output shows the taxonomic IDs of the 13 sequences, 
with their Akaike weight confidence scores attributed to the output
(see `attr(,"score")` on the third-to-last line). 
A few of the sequences simply returned 'Eukaryota', which 
doesn't seem too informative; however this is a fairly typical feature of eDNA datasets. 
Of course some sequences may have come from cryptic species that are completely new to science, 
but in the majority of cases these inconclusive results are probably just 
pseudo genes, chimeras and other PCR artifacts. 
It should be noted that in some situations even previously documented sequences 
can score similarly against both HMMs at certain nodes,
and hence produce an inconclusive classification. 
This may be circumvented by reducing the `threshold` parameter or setting 
`decay = FALSE`, but users are advised against the excessive relaxation of these 
parameters since it may increase the chance of returning spurious classifications 
(extremely rare using the conservative default values of 
`0.9` and `TRUE`, respectively). 
Further testing and optimization may help to address some of these 'best practice' 
considerations, with this constituting an area of ongoing research.    


##Concluding remarks
This basic introduction to the insect package has outlined the steps involved
in parsing paired-end NGS data, and filtering, trimming primers, de-replication, 
and taxonomic identification using a pre-built classification tree. 
Future tutorials will deal with importing and filtering data in various stages of 
pre-processing, generating and curating local sequence databases, 
building classification trees, and tabulating output with the help of 
the NCBI taxon database.

The **insect** package is released under the GPL-3 license, and is free to distribute
under certain conditions; however it comes with no warranty. Please direct bug 
reports to the [GitHub issues page](http://github.com/shaunpwilkinson/insect/issues) 
or email/DM the author directly on [twitter](https://twitter.com/wilkinshau). 
Any feedback is much appreciated.


## Acknowledgements 
This software was developed with funding from a Rutherford Foundation Postdoctoral 
Research Fellowship from the Royal Society of New Zealand. Thanks to Molly Trimmers 
for helpful discussion and sharing COI data, and to Danyl McLauchlan and 
Dinindu Senanayake for assistance with high performance computing facilities. 

## References 
